[
    {
        "functionName": "test_cratesio",
        "className": null,
        "fileName": "/tests/test_cratesio.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'cratesio'}) == '0.1.0'\n",
        "CUT_1": "name = conf.get('cratesio') or name\ndata = await cache.get_json(API_URL % name)\nversion = [v['num'] for v in data['versions'] if not v['yanked']][0]\nreturn version\n",
        "CUT_2": "name = conf.get('cratesio') or name\ndata = await cache.get_json(API_URL % name)\nversion = [v['num'] for v in data['versions'] if not v['yanked']][0]\nreturn version\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_aur",
        "className": null,
        "fileName": "/tests/test_aur.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('ssed', {'source': 'aur'}) == '3.62-2'\n",
        "CUT_1": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_2": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_aur_strip_release",
        "className": null,
        "fileName": "/tests/test_aur.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('ssed', {'source': 'aur', 'strip_release': 1}\n    ) == '3.62'\n",
        "CUT_1": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_2": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_3": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_4": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_5": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n"
    },
    {
        "functionName": "test_aur_use_last_modified",
        "className": null,
        "fileName": "/tests/test_aur.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('ssed', {'source': 'aur', 'use_last_modified': True}\n    ) == '3.62-2-20150725052412'\n",
        "CUT_1": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_2": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "if level == 'exception':\n    event['exc_info'] = True\nreturn event\n"
    },
    {
        "functionName": "test_debianpkg",
        "className": null,
        "fileName": "/tests/test_debianpkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'debianpkg'}\n    ) == '0.1.7-1'\n",
        "CUT_1": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_2": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_3": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n",
        "CUT_4": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n",
        "CUT_5": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n"
    },
    {
        "functionName": "test_debianpkg_strip_release",
        "className": null,
        "fileName": "/tests/test_debianpkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'debianpkg',\n    'strip_release': 1}) == '0.1.7'\n",
        "CUT_1": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_2": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_4": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_5": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n"
    },
    {
        "functionName": "test_debianpkg_suite",
        "className": null,
        "fileName": "/tests/test_debianpkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'debianpkg',\n    'suite': 'buster'}) == '0.1.6-1'\n",
        "CUT_1": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_2": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_3": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n",
        "CUT_4": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_container",
        "className": null,
        "fileName": "/tests/test_container.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('hello-world', {'source': 'container', 'container':\n    'library/hello-world', 'include_regex': 'linux'}) == 'linux'\n",
        "CUT_1": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_2": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_3": "image_path = conf.get('container', name)\nregistry_host = conf.get('registry', 'docker.io')\nif registry_host == 'docker.io':\n    registry_host = 'registry-1.docker.io'\nauth_info = await cache.get(registry_host, get_registry_auth_info)\nkey = image_path, registry_host, auth_info\nreturn await cache.get(key, get_container_tags)\n",
        "CUT_4": "image_path = conf.get('container', name)\nregistry_host = conf.get('registry', 'docker.io')\nif registry_host == 'docker.io':\n    registry_host = 'registry-1.docker.io'\nauth_info = await cache.get(registry_host, get_registry_auth_info)\nkey = image_path, registry_host, auth_info\nreturn await cache.get(key, get_container_tags)\n",
        "CUT_5": "\"\"\"\n  Parse WWW-Authenticate header used in OAuth2 authentication for container\n  registries. This is NOT RFC-compliant!\n\n  Simplified from http.parse_www_authenticate_header in Werkzeug (BSD license)\n  \"\"\"\nauth_type, auth_info = header.split(None, 1)\nresult = {}\nfor item in parse_http_list(auth_info):\n    name, value = item.split('=', 1)\n    if value[:1] == value[-1:] == '\"':\n        value = value[1:-1]\n    result[name] = value\nreturn auth_type, result\n"
    },
    {
        "functionName": "setup_module",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "global temp_dir, db_path\ntemp_dir = tempfile.TemporaryDirectory()\ntemp_path = pathlib.Path(temp_dir.name)\npkg_path = temp_path / 'test-pkg'\npkg_path.mkdir()\nwith (pkg_path / 'PKGBUILD').open('w') as f:\n    f.write(\n        \"\"\"pkgname=test-pkg\npkgver=1.2.3\npkgrel=4\narch=(any)\nprovides=(\"test-provides=5.6-7\" \"test-provides-unversioned\")\n\"\"\"\n        )\nsubprocess.check_call(['makepkg', '--nosign'], cwd=pkg_path)\npkg_file = subprocess.check_output(['makepkg', '--packagelist'], cwd=\n    pkg_path, text=True).strip()\ndb_path = pkg_path / 'test-db'\ndb_path.mkdir()\nrepo_path = db_path / 'sync'\nrepo_path.mkdir()\nsubprocess.check_call(['repo-add', repo_path / 'test-repo.db.tar.gz', \n    pkg_path / pkg_file])\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "config.addinivalue_line('markers',\n    'needs_net: mark test to require Internet access')\n",
        "CUT_4": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_5": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n"
    },
    {
        "functionName": "teardown_module",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "temp_dir.cleanup()\n",
        "CUT_1": "\"\"\"\n  handler: specify a handler instead of default StreamHandler\n  color:   boolean, force color to be on / off. Default to be on only when\n           ``handler`` isn't specified and the term supports color\n  \"\"\"\nlogger = logging.getLogger()\nif handler is None:\n    h = logging.StreamHandler()\nelse:\n    h = handler\nif color is None and handler is None:\n    color = support_color()\nformatter = TornadoLogFormatter(color=color)\nh.setLevel(level)\nh.setFormatter(formatter)\nlogger.setLevel(level)\nlogger.addHandler(h)\n",
        "CUT_2": "\"\"\"return True if should stop\"\"\"\nprocessors = [slogconf.exc_info, slogconf.filter_exc]\nlogger_factory = None\nif args.logger in ['pretty', 'both']:\n    slogconf.fix_logging()\n    nicelogger.enable_pretty_logging(getattr(logging, args.logging.upper()))\n    processors.append(slogconf.stdlib_renderer)\n    if args.logger == 'pretty':\n        logger_factory = structlog.PrintLoggerFactory(file=open(os.devnull,\n            'w'))\n        processors.append(slogconf.null_renderer)\nif args.logger in ['json', 'both']:\n    processors.extend([structlog.processors.format_exc_info, slogconf.\n        json_renderer])\nif logger_factory is None:\n    logfile = args.json_log_fd or sys.stdout\n    logger_factory = structlog.PrintLoggerFactory(file=logfile)\nstructlog.configure(processors=processors, logger_factory=logger_factory)\nif args.version:\n    progname = os.path.basename(sys.argv[0])\n    print(f'{progname} v{__version__}')\n    return True\nreturn False\n",
        "CUT_3": "evt = event['event']\nif evt == 'up-to-date':\n    msg = 'up-to-date, version %s' % event['version']\n    del event['version']\nelif evt == 'updated':\n    if event.get('old_version'):\n        msg = 'updated from %(old_version)s to %(version)s' % event\n    else:\n        msg = 'updated to %(version)s' % event\n    del event['version'], event['old_version']\nelse:\n    msg = evt\nif 'name' in event:\n    msg = f\"{event['name']}: {msg}\"\n    del event['name']\nevent['msg'] = msg\nreturn event\n",
        "CUT_4": "raise NotImplementedError('Using vercmp but pyalpm can not be imported!')\n",
        "CUT_5": "for fu in asyncio.as_completed(futures):\n    await fu\n"
    },
    {
        "functionName": "test_alpm",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('test-pkg', {'source': 'alpm', 'dbpath': str(\n    db_path), 'repo': 'test-repo'}) == '1.2.3-4'\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_4": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_5": "dbpath, repo = info\nhandle = Handle('/', dbpath)\ndb = handle.register_syncdb(repo, 0)\nreturn handle, db\n"
    },
    {
        "functionName": "test_alpm_strip",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('test-pkg', {'source': 'alpm', 'dbpath': str(\n    db_path), 'repo': 'test-repo', 'strip_release': True}) == '1.2.3'\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_4": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_5": "dbpath, repo = info\nhandle = Handle('/', dbpath)\ndb = handle.register_syncdb(repo, 0)\nreturn handle, db\n"
    },
    {
        "functionName": "test_alpm_provided",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('test-pkg', {'source': 'alpm', 'dbpath': str(\n    db_path), 'repo': 'test-repo', 'provided': 'test-provides'}) == '5.6-7'\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_4": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_5": "config.addinivalue_line('markers',\n    'needs_net: mark test to require Internet access')\n"
    },
    {
        "functionName": "test_alpm_provided_strip",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('test-pkg', {'source': 'alpm', 'dbpath': str(\n    db_path), 'repo': 'test-repo', 'provided': 'test-provides',\n    'strip_release': True}) == '5.6'\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_4": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_5": "config.addinivalue_line('markers',\n    'needs_net: mark test to require Internet access')\n"
    },
    {
        "functionName": "test_alpm_missing_repo",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "with pytest.raises(RuntimeError):\n    await get_version('test-pkg', {'source': 'alpm', 'dbpath': str(db_path),\n        'repo': 'wrong-repo'})\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_4": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_5": "dbpath, repo = info\nhandle = Handle('/', dbpath)\ndb = handle.register_syncdb(repo, 0)\nreturn handle, db\n"
    },
    {
        "functionName": "test_alpm_missing_pkg",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "with pytest.raises(RuntimeError):\n    await get_version('wrong-pkg', {'source': 'alpm', 'dbpath': str(db_path\n        ), 'repo': 'test-repo'})\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_4": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_5": "dbpath, repo = info\nhandle = Handle('/', dbpath)\ndb = handle.register_syncdb(repo, 0)\nreturn handle, db\n"
    },
    {
        "functionName": "test_alpm_missing_provides",
        "className": null,
        "fileName": "/tests/test_alpm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "with pytest.raises(RuntimeError):\n    await get_version('test-pkg', {'source': 'alpm', 'dbpath': str(db_path),\n        'repo': 'test-repo', 'provided': 'wrong-provides'})\n",
        "CUT_1": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_2": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_4": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_5": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n"
    },
    {
        "functionName": "test_npm",
        "className": null,
        "fileName": "/tests/test_npm.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'npm'}) == '0.0.0'\n",
        "CUT_1": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_2": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_3": "headers = {'Accept': 'application/vnd.npm.install-v1+json', 'Range':\n    'bytes=0-1023'}\nres = await session.get(url, headers=headers)\nreturn res.body\n",
        "CUT_4": "headers = {'Accept': 'application/vnd.npm.install-v1+json', 'Range':\n    'bytes=0-1023'}\nres = await session.get(url, headers=headers)\nreturn res.body\n",
        "CUT_5": "key = conf.get('npm', name)\ndata = await cache.get(NPM_URL % key, get_first_1k)\ndist_tags = json.loads(re.search(b'\"dist-tags\":({.*?})', data).group(1))\nreturn dist_tags['latest']\n"
    },
    {
        "functionName": "test_github",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'harry-sanabria/ReleaseTestRepo'}) == '20140122.012101'\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_github_default_not_master",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'MariaDB/server'}) is not None\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "assert self.func is not None\ntries = entry.get('tries', None)\nif tries is not None:\n    ctx_tries.set(tries)\nproxy = entry.get('proxy', None)\nif proxy is not None:\n    ctx_proxy.set(proxy)\nua = entry.get('user_agent', None)\nif ua is not None:\n    ctx_ua.set(ua)\ntry:\n    async with self.task_sem:\n        version = await self.func(name, entry, cache=self.cache, keymanager\n            =self.keymanager)\n    await self.result_q.put(RawResult(name, version, entry))\nexcept Exception as e:\n    await self.result_q.put(RawResult(name, e, entry))\n",
        "CUT_4": "assert self.func is not None\ntries = entry.get('tries', None)\nif tries is not None:\n    ctx_tries.set(tries)\nproxy = entry.get('proxy', None)\nif proxy is not None:\n    ctx_proxy.set(proxy)\nua = entry.get('user_agent', None)\nif ua is not None:\n    ctx_ua.set(ua)\ntry:\n    async with self.task_sem:\n        version = await self.func(name, entry, cache=self.cache, keymanager\n            =self.keymanager)\n    await self.result_q.put(RawResult(name, version, entry))\nexcept Exception as e:\n    await self.result_q.put(RawResult(name, e, entry))\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_github_latest_release",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'harry-sanabria/ReleaseTestRepo', 'use_latest_release': True}\n    ) == 'release3'\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "if level == 'exception':\n    event['exc_info'] = True\nreturn event\n"
    },
    {
        "functionName": "test_github_max_tag",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'harry-sanabria/ReleaseTestRepo', 'use_max_tag': True}) == 'second_release'\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_4": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_5": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_github_max_tag_with_ignored",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'harry-sanabria/ReleaseTestRepo', 'use_max_tag': True, 'ignored':\n    'second_release release3'}) == 'first_release'\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_4": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_5": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_github_with_path",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'petronny/ReleaseTestRepo', 'path': 'test_directory'}) == '20140122.012101'\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "try:\n    config = toml.load(file)\nexcept (OSError, toml.TomlDecodeError) as e:\n    raise FileLoadError('version configuration file', file, e)\nver_files: Optional[Tuple[Path, Path]] = None\nkeymanager = KeyManager(None)\nsource_configs = {}\nif '__config__' in config:\n    c = config.pop('__config__')\n    d = Path(file).parent\n    if 'oldver' in c and 'newver' in c:\n        oldver_s = os.path.expandvars(os.path.expanduser(c.get('oldver')))\n        oldver = d / oldver_s\n        newver_s = os.path.expandvars(os.path.expanduser(c.get('newver')))\n        newver = d / newver_s\n        ver_files = oldver, newver\n    if use_keymanager:\n        keyfile = c.get('keyfile')\n        if keyfile:\n            keyfile_s = os.path.expandvars(os.path.expanduser(c.get('keyfile'))\n                )\n            keyfile = d / keyfile_s\n        keymanager = KeyManager(keyfile)\n    if 'source' in c:\n        source_configs = c['source']\n    max_concurrency = c.get('max_concurrency', 20)\n    proxy = c.get('proxy')\n    httplib = c.get('httplib', None)\n    http_timeout = c.get('http_timeout', 20)\nelse:\n    max_concurrency = 20\n    proxy = None\n    httplib = None\n    http_timeout = 20\nreturn cast(Entries, config), Options(ver_files, max_concurrency, proxy,\n    keymanager, source_configs, httplib, http_timeout)\n",
        "CUT_4": "try:\n    config = toml.load(file)\nexcept (OSError, toml.TomlDecodeError) as e:\n    raise FileLoadError('version configuration file', file, e)\nver_files: Optional[Tuple[Path, Path]] = None\nkeymanager = KeyManager(None)\nsource_configs = {}\nif '__config__' in config:\n    c = config.pop('__config__')\n    d = Path(file).parent\n    if 'oldver' in c and 'newver' in c:\n        oldver_s = os.path.expandvars(os.path.expanduser(c.get('oldver')))\n        oldver = d / oldver_s\n        newver_s = os.path.expandvars(os.path.expanduser(c.get('newver')))\n        newver = d / newver_s\n        ver_files = oldver, newver\n    if use_keymanager:\n        keyfile = c.get('keyfile')\n        if keyfile:\n            keyfile_s = os.path.expandvars(os.path.expanduser(c.get('keyfile'))\n                )\n            keyfile = d / keyfile_s\n        keymanager = KeyManager(keyfile)\n    if 'source' in c:\n        source_configs = c['source']\n    max_concurrency = c.get('max_concurrency', 20)\n    proxy = c.get('proxy')\n    httplib = c.get('httplib', None)\n    http_timeout = c.get('http_timeout', 20)\nelse:\n    max_concurrency = 20\n    proxy = None\n    httplib = None\n    http_timeout = 20\nreturn cast(Entries, config), Options(ver_files, max_concurrency, proxy,\n    keymanager, source_configs, httplib, http_timeout)\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_github_with_path_and_branch",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'petronny/ReleaseTestRepo', 'branch': 'test', 'path':\n    'test_directory/test_directory'}) == '20190128.113201'\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "try:\n    config = toml.load(file)\nexcept (OSError, toml.TomlDecodeError) as e:\n    raise FileLoadError('version configuration file', file, e)\nver_files: Optional[Tuple[Path, Path]] = None\nkeymanager = KeyManager(None)\nsource_configs = {}\nif '__config__' in config:\n    c = config.pop('__config__')\n    d = Path(file).parent\n    if 'oldver' in c and 'newver' in c:\n        oldver_s = os.path.expandvars(os.path.expanduser(c.get('oldver')))\n        oldver = d / oldver_s\n        newver_s = os.path.expandvars(os.path.expanduser(c.get('newver')))\n        newver = d / newver_s\n        ver_files = oldver, newver\n    if use_keymanager:\n        keyfile = c.get('keyfile')\n        if keyfile:\n            keyfile_s = os.path.expandvars(os.path.expanduser(c.get('keyfile'))\n                )\n            keyfile = d / keyfile_s\n        keymanager = KeyManager(keyfile)\n    if 'source' in c:\n        source_configs = c['source']\n    max_concurrency = c.get('max_concurrency', 20)\n    proxy = c.get('proxy')\n    httplib = c.get('httplib', None)\n    http_timeout = c.get('http_timeout', 20)\nelse:\n    max_concurrency = 20\n    proxy = None\n    httplib = None\n    http_timeout = 20\nreturn cast(Entries, config), Options(ver_files, max_concurrency, proxy,\n    keymanager, source_configs, httplib, http_timeout)\n",
        "CUT_4": "try:\n    config = toml.load(file)\nexcept (OSError, toml.TomlDecodeError) as e:\n    raise FileLoadError('version configuration file', file, e)\nver_files: Optional[Tuple[Path, Path]] = None\nkeymanager = KeyManager(None)\nsource_configs = {}\nif '__config__' in config:\n    c = config.pop('__config__')\n    d = Path(file).parent\n    if 'oldver' in c and 'newver' in c:\n        oldver_s = os.path.expandvars(os.path.expanduser(c.get('oldver')))\n        oldver = d / oldver_s\n        newver_s = os.path.expandvars(os.path.expanduser(c.get('newver')))\n        newver = d / newver_s\n        ver_files = oldver, newver\n    if use_keymanager:\n        keyfile = c.get('keyfile')\n        if keyfile:\n            keyfile_s = os.path.expandvars(os.path.expanduser(c.get('keyfile'))\n                )\n            keyfile = d / keyfile_s\n        keymanager = KeyManager(keyfile)\n    if 'source' in c:\n        source_configs = c['source']\n    max_concurrency = c.get('max_concurrency', 20)\n    proxy = c.get('proxy')\n    httplib = c.get('httplib', None)\n    http_timeout = c.get('http_timeout', 20)\nelse:\n    max_concurrency = 20\n    proxy = None\n    httplib = None\n    http_timeout = 20\nreturn cast(Entries, config), Options(ver_files, max_concurrency, proxy,\n    keymanager, source_configs, httplib, http_timeout)\n",
        "CUT_5": "config.addinivalue_line('markers',\n    'needs_net: mark test to require Internet access')\n"
    },
    {
        "functionName": "test_github_max_tag_with_include",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "version = await get_version('example', {'source': 'github', 'github':\n    'EFForg/https-everywhere', 'use_max_tag': True, 'include_regex':\n    'chrome-\\\\d.*'})\nassert re.match('chrome-[\\\\d.]+', version)\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_4": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_5": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_github_latest_tag",
        "className": null,
        "fileName": "/tests/test_github.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'github', 'github':\n    'harry-sanabria/ReleaseTestRepo', 'use_latest_tag': True}) == 'release3'\n",
        "CUT_1": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_2": "repo = conf['github']\ntoken = conf.get('token')\nif token is None:\n    token = keymanager.get_key('github')\nuse_latest_tag = conf.get('use_latest_tag', False)\nif use_latest_tag:\n    if not token:\n        raise GetVersionError('token not given but it is required')\n    query = conf.get('query', '')\n    return await cache.get((repo, query, token), get_latest_tag)\nbr = conf.get('branch')\npath = conf.get('path')\nuse_latest_release = conf.get('use_latest_release', False)\nuse_max_tag = conf.get('use_max_tag', False)\nif use_latest_release:\n    url = GITHUB_LATEST_RELEASE % repo\nelif use_max_tag:\n    url = GITHUB_MAX_TAG % repo\nelse:\n    url = GITHUB_URL % repo\n    parameters = {}\n    if br:\n        parameters['sha'] = br\n    if path:\n        parameters['path'] = path\n    url += '?' + urlencode(parameters)\nheaders = {'Accept': 'application/vnd.github.quicksilver-preview+json'}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    tags = [ref['ref'].split('/', 2)[-1] for ref in data]\n    if not tags:\n        raise GetVersionError('No tag found in upstream repository.')\n    return tags\nif use_latest_release:\n    if 'tag_name' not in data:\n        raise GetVersionError('No release found in upstream repository.')\n    version = data['tag_name']\nelse:\n    version = data[0]['commit']['committer']['date'].rstrip('Z').replace('-',\n        '').replace(':', '').replace('T', '.')\nreturn version\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "if level == 'exception':\n    event['exc_info'] = True\nreturn event\n"
    },
    {
        "functionName": "test_git",
        "className": null,
        "fileName": "/tests/test_git.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'git', 'git':\n    'https://gitlab.com/gitlab-org/gitlab-test.git'}) == 'v1.1.1'\n",
        "CUT_1": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_2": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_3": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_4": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_5": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n"
    },
    {
        "functionName": "test_cpan",
        "className": null,
        "fileName": "/tests/test_cpan.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('POE-Component-Server-HTTPServer', {'source': 'cpan'}\n    ) == '0.9.2'\n",
        "CUT_1": "key = conf.get('cpan', name)\ndata = await cache.get_json(CPAN_URL % key)\nreturn str(data['version'])\n",
        "CUT_2": "key = conf.get('cpan', name)\ndata = await cache.get_json(CPAN_URL % key)\nreturn str(data['version'])\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_cmd",
        "className": null,
        "fileName": "/tests/test_cmd.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'cmd', 'cmd': 'echo Meow'}\n    ) == 'Meow'\n",
        "CUT_1": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_2": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_3": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_4": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_5": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n"
    },
    {
        "functionName": "test_cmd_complex",
        "className": null,
        "fileName": "/tests/test_cmd.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'cmd', 'cmd':\n    \"echo Meow | sed 's/meow/woof/i'\"}) == 'woof'\n",
        "CUT_1": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_2": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_3": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_4": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_5": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n"
    },
    {
        "functionName": "test_cmd_with_percent",
        "className": null,
        "fileName": "/tests/test_cmd.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "test_conf = \"\"\"[example]\nsource = \"cmd\"\ncmd = \"date +%Y-%m-%d\\\"\"\"\"\ndate = await run_str(test_conf)\nexpected = time.strftime('%Y-%m-%d')\nassert date == expected\n",
        "CUT_1": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_2": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_3": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_4": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_5": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n"
    },
    {
        "functionName": "base64_encode",
        "className": null,
        "fileName": "/tests/test_regex.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "return base64.b64encode(s.encode('utf-8')).decode('ascii')\n",
        "CUT_1": "\"\"\"Convert reponse content to JSON.\"\"\"\nreturn _json.loads(self.body.decode('utf-8'))\n",
        "CUT_2": "\"\"\"Convert reponse content to JSON.\"\"\"\nreturn _json.loads(self.body.decode('utf-8'))\n",
        "CUT_3": "repo_xml_url = _ANDROID_REPO_MANIFESTS[repo]\nres = await session.get(repo_xml_url)\ndata = res.body.decode('utf-8')\nrepo_manifest = ElementTree.fromstring(data)\nreturn repo_manifest\n",
        "CUT_4": "repo_xml_url = _ANDROID_REPO_MANIFESTS[repo]\nres = await session.get(repo_xml_url)\ndata = res.body.decode('utf-8')\nrepo_manifest = ElementTree.fromstring(data)\nreturn repo_manifest\n",
        "CUT_5": "if color is None:\n    color = support_color()\nif color:\n    import curses\n    curses.setupterm()\n    if sys.hexversion < 50463728:\n        fg_color = str(curses.tigetstr('setaf') or curses.tigetstr('setf') or\n            '', 'ascii')\n    else:\n        fg_color = curses.tigetstr('setaf') or curses.tigetstr('setf') or b''\n    self.blue = str(curses.tparm(fg_color, 4), 'ascii')\n    self.yellow = str(curses.tparm(fg_color, 3), 'ascii')\n    self.green = str(curses.tparm(fg_color, 2), 'ascii')\n    self.red = str(curses.tparm(fg_color, 1), 'ascii')\n    self.bright_red = str(curses.tparm(fg_color, 9), 'ascii')\n    self.normal = str(curses.tigetstr('sgr0'), 'ascii')\nelse:\n    (self.blue) = (self.yellow) = (self.green) = (self.red) = (self.bright_red\n        ) = (self.normal) = ''\n"
    },
    {
        "functionName": "test_regex_httpbin_default_user_agent",
        "className": null,
        "fileName": "/tests/test_regex.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "ua = await get_version('example', {'source': 'regex', 'url': httpbin.url +\n    '/get', 'regex': '\"User-Agent\":\\\\s*\"([^\"]+)\"'})\nassert ua.startswith('lilydjwg/nvchecker')\n",
        "CUT_1": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_2": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_3": "t = tries.get()\np = proxy.get()\nua = user_agent.get()\nheaders = headers.copy()\nheaders.setdefault('User-Agent', ua)\nfor i in range(1, t + 1):\n    try:\n        return await self.request_impl(url, method=method, headers=headers,\n            params=params, json=json, proxy=p or None)\n    except TemporaryError as e:\n        if i == t:\n            raise\n        else:\n            logger.warning('temporary error, retrying', tries=i, exc_info=e)\n            continue\nraise Exception('shoud not reach')\n",
        "CUT_4": "t = tries.get()\np = proxy.get()\nua = user_agent.get()\nheaders = headers.copy()\nheaders.setdefault('User-Agent', ua)\nfor i in range(1, t + 1):\n    try:\n        return await self.request_impl(url, method=method, headers=headers,\n            params=params, json=json, proxy=p or None)\n    except TemporaryError as e:\n        if i == t:\n            raise\n        else:\n            logger.warning('temporary error, retrying', tries=i, exc_info=e)\n            continue\nraise Exception('shoud not reach')\n",
        "CUT_5": "assert self.func is not None\ntries = entry.get('tries', None)\nif tries is not None:\n    ctx_tries.set(tries)\nproxy = entry.get('proxy', None)\nif proxy is not None:\n    ctx_proxy.set(proxy)\nua = entry.get('user_agent', None)\nif ua is not None:\n    ctx_ua.set(ua)\ntry:\n    async with self.task_sem:\n        version = await self.func(name, entry, cache=self.cache, keymanager\n            =self.keymanager)\n    await self.result_q.put(RawResult(name, version, entry))\nexcept Exception as e:\n    await self.result_q.put(RawResult(name, e, entry))\n"
    },
    {
        "functionName": "test_regex_httpbin_user_agent",
        "className": null,
        "fileName": "/tests/test_regex.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'regex', 'url': httpbin.url +\n    '/get', 'regex': '\"User-Agent\":\\\\s*\"(\\\\w+)\"', 'user_agent': 'Meow'}\n    ) == 'Meow'\n",
        "CUT_1": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_2": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_3": "t = tries.get()\np = proxy.get()\nua = user_agent.get()\nheaders = headers.copy()\nheaders.setdefault('User-Agent', ua)\nfor i in range(1, t + 1):\n    try:\n        return await self.request_impl(url, method=method, headers=headers,\n            params=params, json=json, proxy=p or None)\n    except TemporaryError as e:\n        if i == t:\n            raise\n        else:\n            logger.warning('temporary error, retrying', tries=i, exc_info=e)\n            continue\nraise Exception('shoud not reach')\n",
        "CUT_4": "t = tries.get()\np = proxy.get()\nua = user_agent.get()\nheaders = headers.copy()\nheaders.setdefault('User-Agent', ua)\nfor i in range(1, t + 1):\n    try:\n        return await self.request_impl(url, method=method, headers=headers,\n            params=params, json=json, proxy=p or None)\n    except TemporaryError as e:\n        if i == t:\n            raise\n        else:\n            logger.warning('temporary error, retrying', tries=i, exc_info=e)\n            continue\nraise Exception('shoud not reach')\n",
        "CUT_5": "global NPM_URL\nurl = config.get('registry')\nif url:\n    NPM_URL = f\"{url.rstrip('/')}/%s\"\n"
    },
    {
        "functionName": "test_regex",
        "className": null,
        "fileName": "/tests/test_regex.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'regex', 'url': httpbin.url +\n    '/base64/' + base64_encode('version 1.12 released'), 'regex':\n    'version ([0-9.]+)'}) == '1.12'\n",
        "CUT_1": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_2": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_3": "pkg = conf.get('anitya')\nurl = URL.format(pkg=pkg)\ndata = await cache.get_json(url)\nreturn data['version']\n",
        "CUT_4": "pkg = conf.get('anitya')\nurl = URL.format(pkg=pkg)\ndata = await cache.get_json(url)\nreturn data['version']\n",
        "CUT_5": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n"
    },
    {
        "functionName": "test_missing_ok",
        "className": null,
        "fileName": "/tests/test_regex.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'regex', 'url': httpbin.url +\n    '/base64/' + base64_encode('something not there'), 'regex': 'foobar',\n    'missing_ok': True}) is None\n",
        "CUT_1": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_2": "conf = dict(info)\ntry:\n    regex = re.compile(conf['regex'])\nexcept sre_constants.error as e:\n    raise GetVersionError('bad regex', exc_info=e)\nencoding = conf.get('encoding', 'latin1')\nres = await session.get(conf['url'])\nbody = res.body.decode(encoding)\ntry:\n    version = regex.findall(body)\nexcept ValueError:\n    version = None\n    if not conf.get('missing_ok', False):\n        raise GetVersionError('version string not found.')\nreturn version\n",
        "CUT_3": "pkg = conf.get('anitya')\nurl = URL.format(pkg=pkg)\ndata = await cache.get_json(url)\nreturn data['version']\n",
        "CUT_4": "pkg = conf.get('anitya')\nurl = URL.format(pkg=pkg)\ndata = await cache.get_json(url)\nreturn data['version']\n",
        "CUT_5": "global NPM_URL\nurl = config.get('registry')\nif url:\n    NPM_URL = f\"{url.rstrip('/')}/%s\"\n"
    },
    {
        "functionName": "test_gitea",
        "className": null,
        "fileName": "/tests/test_gitea.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "ver = await get_version('example', {'source': 'gitea', 'gitea': 'gitea/tea'})\nassert len(ver) == 8\nassert ver.isdigit()\n",
        "CUT_1": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_2": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_3": "repo = urllib.parse.quote(conf['gitea'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitea.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITEA_MAX_TAG % (host, repo)\nelse:\n    url = GITEA_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitea_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['commit']['committer']['date'].split('T', 1)[0].replace(\n        '-', '')\nreturn version\n",
        "CUT_4": "repo = urllib.parse.quote(conf['gitea'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitea.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITEA_MAX_TAG % (host, repo)\nelse:\n    url = GITEA_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitea_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['commit']['committer']['date'].split('T', 1)[0].replace(\n        '-', '')\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_gitea_max_tag_with_include",
        "className": null,
        "fileName": "/tests/test_gitea.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'gitea', 'gitea':\n    'gitea/tea', 'use_max_tag': True, 'include_regex': 'v0\\\\.3.*'}) == 'v0.3.1'\n",
        "CUT_1": "repo = urllib.parse.quote(conf['gitea'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitea.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITEA_MAX_TAG % (host, repo)\nelse:\n    url = GITEA_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitea_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['commit']['committer']['date'].split('T', 1)[0].replace(\n        '-', '')\nreturn version\n",
        "CUT_2": "repo = urllib.parse.quote(conf['gitea'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitea.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITEA_MAX_TAG % (host, repo)\nelse:\n    url = GITEA_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitea_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['Authorization'] = f'token {token}'\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['commit']['committer']['date'].split('T', 1)[0].replace(\n        '-', '')\nreturn version\n",
        "CUT_3": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_4": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_5": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_android_addon",
        "className": null,
        "fileName": "/tests/test_android_sdk.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('android-google-play-apk-expansion', {'source':\n    'android_sdk', 'android_sdk': 'extras;google;market_apk_expansion',\n    'repo': 'addon'}) == '1.r03'\n",
        "CUT_1": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_2": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "repo = conf['repo']\npkg_path_prefix = conf['android_sdk']\nchannels = [_CHANNEL_MAP[channel] for channel in conf.get('channel',\n    'stable').split(',')]\nrepo_manifest = await cache.get(repo, _get_repo_manifest)\nfor pkg in repo_manifest.findall('.//remotePackage'):\n    if not pkg.attrib['path'].startswith(pkg_path_prefix):\n        continue\n    channelRef = pkg.find('./channelRef')\n    if channelRef.attrib['ref'] not in channels:\n        continue\n    for archive in pkg.findall('./archives/archive'):\n        host_os = archive.find('./host-os')\n        if host_os is not None and host_os.text != 'linux':\n            continue\n        archive_url = archive.find('./complete/url').text\n        rev = pkg.find('./revision')\n        rev_strs = []\n        for part in ('major', 'minor', 'micro'):\n            part_node = rev.find('./' + part)\n            if part_node is not None:\n                rev_strs.append(part_node.text)\n        filename, ext = os.path.splitext(archive_url)\n        rel_str = filename.rsplit('-')[-1]\n        mobj = re.match('r\\\\d+', rel_str)\n        if mobj:\n            rev_strs.append(rel_str)\n        return '.'.join(rev_strs)\n"
    },
    {
        "functionName": "test_android_package",
        "className": null,
        "fileName": "/tests/test_android_sdk.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('android-sdk-cmake', {'source': 'android_sdk',\n    'android_sdk': 'cmake;', 'repo': 'package'}) == '3.6.4111459'\n",
        "CUT_1": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_2": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "repo = conf['repo']\npkg_path_prefix = conf['android_sdk']\nchannels = [_CHANNEL_MAP[channel] for channel in conf.get('channel',\n    'stable').split(',')]\nrepo_manifest = await cache.get(repo, _get_repo_manifest)\nfor pkg in repo_manifest.findall('.//remotePackage'):\n    if not pkg.attrib['path'].startswith(pkg_path_prefix):\n        continue\n    channelRef = pkg.find('./channelRef')\n    if channelRef.attrib['ref'] not in channels:\n        continue\n    for archive in pkg.findall('./archives/archive'):\n        host_os = archive.find('./host-os')\n        if host_os is not None and host_os.text != 'linux':\n            continue\n        archive_url = archive.find('./complete/url').text\n        rev = pkg.find('./revision')\n        rev_strs = []\n        for part in ('major', 'minor', 'micro'):\n            part_node = rev.find('./' + part)\n            if part_node is not None:\n                rev_strs.append(part_node.text)\n        filename, ext = os.path.splitext(archive_url)\n        rel_str = filename.rsplit('-')[-1]\n        mobj = re.match('r\\\\d+', rel_str)\n        if mobj:\n            rev_strs.append(rel_str)\n        return '.'.join(rev_strs)\n"
    },
    {
        "functionName": "test_android_package_channel",
        "className": null,
        "fileName": "/tests/test_android_sdk.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('android-sdk-cmake', {'source': 'android_sdk',\n    'android_sdk': 'cmake;', 'repo': 'package', 'channel': 'beta,dev,canary'}\n    ) == '3.18.1'\n",
        "CUT_1": "repo = conf['repo']\npkg_path_prefix = conf['android_sdk']\nchannels = [_CHANNEL_MAP[channel] for channel in conf.get('channel',\n    'stable').split(',')]\nrepo_manifest = await cache.get(repo, _get_repo_manifest)\nfor pkg in repo_manifest.findall('.//remotePackage'):\n    if not pkg.attrib['path'].startswith(pkg_path_prefix):\n        continue\n    channelRef = pkg.find('./channelRef')\n    if channelRef.attrib['ref'] not in channels:\n        continue\n    for archive in pkg.findall('./archives/archive'):\n        host_os = archive.find('./host-os')\n        if host_os is not None and host_os.text != 'linux':\n            continue\n        archive_url = archive.find('./complete/url').text\n        rev = pkg.find('./revision')\n        rev_strs = []\n        for part in ('major', 'minor', 'micro'):\n            part_node = rev.find('./' + part)\n            if part_node is not None:\n                rev_strs.append(part_node.text)\n        filename, ext = os.path.splitext(archive_url)\n        rel_str = filename.rsplit('-')[-1]\n        mobj = re.match('r\\\\d+', rel_str)\n        if mobj:\n            rev_strs.append(rel_str)\n        return '.'.join(rev_strs)\n",
        "CUT_2": "repo = conf['repo']\npkg_path_prefix = conf['android_sdk']\nchannels = [_CHANNEL_MAP[channel] for channel in conf.get('channel',\n    'stable').split(',')]\nrepo_manifest = await cache.get(repo, _get_repo_manifest)\nfor pkg in repo_manifest.findall('.//remotePackage'):\n    if not pkg.attrib['path'].startswith(pkg_path_prefix):\n        continue\n    channelRef = pkg.find('./channelRef')\n    if channelRef.attrib['ref'] not in channels:\n        continue\n    for archive in pkg.findall('./archives/archive'):\n        host_os = archive.find('./host-os')\n        if host_os is not None and host_os.text != 'linux':\n            continue\n        archive_url = archive.find('./complete/url').text\n        rev = pkg.find('./revision')\n        rev_strs = []\n        for part in ('major', 'minor', 'micro'):\n            part_node = rev.find('./' + part)\n            if part_node is not None:\n                rev_strs.append(part_node.text)\n        filename, ext = os.path.splitext(archive_url)\n        rel_str = filename.rsplit('-')[-1]\n        mobj = re.match('r\\\\d+', rel_str)\n        if mobj:\n            rev_strs.append(rel_str)\n        return '.'.join(rev_strs)\n",
        "CUT_3": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_4": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_hackage",
        "className": null,
        "fileName": "/tests/test_hackage.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sessions', {'source': 'hackage'}) == '2008.7.18'\n",
        "CUT_1": "key = conf.get('hackage', name)\ndata = await cache.get_json(HACKAGE_URL % key)\nreturn data['normal-version'][0]\n",
        "CUT_2": "key = conf.get('hackage', name)\ndata = await cache.get_json(HACKAGE_URL % key)\nreturn data['normal-version'][0]\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_packagist",
        "className": null,
        "fileName": "/tests/test_packagist.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('butterfly/example-web-application', {'source':\n    'packagist'}) == '1.2.0'\n",
        "CUT_1": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_2": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_3": "headers = {'Accept': 'application/vnd.npm.install-v1+json', 'Range':\n    'bytes=0-1023'}\nres = await session.get(url, headers=headers)\nreturn res.body\n",
        "CUT_4": "headers = {'Accept': 'application/vnd.npm.install-v1+json', 'Range':\n    'bytes=0-1023'}\nres = await session.get(url, headers=headers)\nreturn res.body\n",
        "CUT_5": "key = conf.get('packagist', name)\ndata = await cache.get_json(PACKAGIST_URL % key)\nversions = {version: details for version, details in data['package'][\n    'versions'].items() if version != 'dev-master'}\nif len(versions):\n    return max(versions, key=lambda version: versions[version]['time'])\n"
    },
    {
        "functionName": "test_archpkg",
        "className": null,
        "fileName": "/tests/test_archpkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('ipw2100-fw', {'source': 'archpkg'}) == '1.3-10'\n",
        "CUT_1": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_2": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_3": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n",
        "CUT_4": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n",
        "CUT_5": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n"
    },
    {
        "functionName": "test_archpkg_strip_release",
        "className": null,
        "fileName": "/tests/test_archpkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('ipw2100-fw', {'source': 'archpkg',\n    'strip_release': True}) == '1.3'\n",
        "CUT_1": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_2": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_4": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_archpkg_provided",
        "className": null,
        "fileName": "/tests/test_archpkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('dbus', {'source': 'archpkg', 'provided':\n    'libdbus-1.so'}) == '3-64'\n",
        "CUT_1": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_2": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_3": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_4": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_archpkg_provided_strip",
        "className": null,
        "fileName": "/tests/test_archpkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('jsoncpp', {'source': 'archpkg', 'provided':\n    'libjsoncpp.so', 'strip_release': True}) == '24'\n",
        "CUT_1": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_2": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_3": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_4": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n",
        "CUT_5": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n"
    },
    {
        "functionName": "test_pacman",
        "className": null,
        "fileName": "/tests/test_pacman.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('ipw2100-fw', {'source': 'pacman'}) == '1.3-10'\n",
        "CUT_1": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_2": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_pacman_strip_release",
        "className": null,
        "fileName": "/tests/test_pacman.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('ipw2100-fw', {'source': 'pacman', 'strip_release': 1}\n    ) == '1.3'\n",
        "CUT_1": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_2": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_4": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_ubuntupkg",
        "className": null,
        "fileName": "/tests/test_ubuntupkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'ubuntupkg'}\n    ) == '0.1.7-1'\n",
        "CUT_1": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_2": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_3": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n",
        "CUT_4": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n",
        "CUT_5": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n"
    },
    {
        "functionName": "test_ubuntupkg_strip_release",
        "className": null,
        "fileName": "/tests/test_ubuntupkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'ubuntupkg',\n    'strip_release': True}) == '0.1.7'\n",
        "CUT_1": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_2": "referree = conf.get('pacman') or name\nc = (\n    \"LANG=C pacman -Si %s | grep -F Version | awk '{print $3}' | head -n 1\" %\n    referree)\nconf['cmd'] = c\nstrip_release = conf.get('strip_release', False)\nversion = await cmd.get_version(name, conf, **kwargs)\nif strip_release and '-' in version:\n    version = version.rsplit('-', 1)[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_4": "pkg = conf.get('archpkg') or name\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndata = await cache.get(pkg, request)\nif not data['results']:\n    raise GetVersionError('Arch package not found')\nr = [r for r in data['results'] if r['repo'] != 'testing'][0]\nif provided:\n    provides = dict(x.split('=', 1) for x in r['provides'] if '=' in x)\n    version = provides.get(provided, None)\n    if strip_release:\n        version = version.split('-', 1)[0]\nelif strip_release:\n    version = r['pkgver']\nelse:\n    version = r['pkgver'] + '-' + r['pkgrel']\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_ubuntupkg_suite",
        "className": null,
        "fileName": "/tests/test_ubuntupkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'ubuntupkg',\n    'suite': 'xenial'}) == '0.1.2-1'\n",
        "CUT_1": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n",
        "CUT_2": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n",
        "CUT_3": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_4": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_ubuntupkg_suite_with_paging",
        "className": null,
        "fileName": "/tests/test_ubuntupkg.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('ffmpeg', {'source': 'ubuntupkg', 'suite': 'xenial'}\n    ) == '7:2.8.17-0ubuntu0.1'\n",
        "CUT_1": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n",
        "CUT_2": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n",
        "CUT_3": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_4": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_anitya",
        "className": null,
        "fileName": "/tests/test_anitya.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('shutter', {'source': 'anitya', 'anitya':\n    'fedora/shutter'}) == '0.94.3'\n",
        "CUT_1": "pkg = conf.get('anitya')\nurl = URL.format(pkg=pkg)\ndata = await cache.get_json(url)\nreturn data['version']\n",
        "CUT_2": "pkg = conf.get('anitya')\nurl = URL.format(pkg=pkg)\ndata = await cache.get_json(url)\nreturn data['version']\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_bitbucket",
        "className": null,
        "fileName": "/tests/test_bitbucket.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'bitbucket', 'bitbucket':\n    'prawee/git-tag'}) == '20150303'\n",
        "CUT_1": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_2": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_3": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_4": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_bitbucket_max_tag",
        "className": null,
        "fileName": "/tests/test_bitbucket.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'bitbucket', 'bitbucket':\n    'prawee/git-tag', 'use_max_tag': True}) == '1.7.0'\n",
        "CUT_1": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_2": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_3": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_4": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_5": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_bitbucket_max_tag_with_ignored",
        "className": null,
        "fileName": "/tests/test_bitbucket.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'bitbucket', 'bitbucket':\n    'prawee/git-tag', 'use_max_tag': True, 'ignored': '1.6.0 1.7.0'}) == 'v1.5'\n",
        "CUT_1": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_2": "git = conf['git']\ncmd = f'git ls-remote -t --refs {git}'\ndata = await cache.get(cmd, run_cmd)\nversions = [line.split('refs/tags/')[1] for line in data.splitlines()]\nreturn versions\n",
        "CUT_3": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_4": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_5": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_gems",
        "className": null,
        "fileName": "/tests/test_gems.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'gems'}) == '1.0.2'\n",
        "CUT_1": "key = conf.get('gems', name)\ndata = await cache.get_json(GEMS_URL % key)\nreturn [item['number'] for item in data]\n",
        "CUT_2": "key = conf.get('gems', name)\ndata = await cache.get_json(GEMS_URL % key)\nreturn [item['number'] for item in data]\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_repology",
        "className": null,
        "fileName": "/tests/test_repology.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('ssed', {'source': 'repology', 'repo': 'aur'}\n    ) == '3.62'\n",
        "CUT_1": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_2": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_3": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_4": "aurnames = {conf.get('aur', name) for name, conf in batch}\nresults = await aur_results.get_multiple(aurnames)\nret: Dict[str, VersionResult] = {}\nfor name, conf in batch:\n    aurname = conf.get('aur', name)\n    use_last_modified = conf.get('use_last_modified', False)\n    strip_release = conf.get('strip_release', False)\n    result = results.get(aurname)\n    if result is None:\n        ret[name] = GetVersionError('AUR upstream not found')\n        continue\n    version = result['Version']\n    if use_last_modified:\n        version += '-' + datetime.utcfromtimestamp(result['LastModified']\n            ).strftime('%Y%m%d%H%M%S')\n    if strip_release and '-' in version:\n        version = version.rsplit('-', 1)[0]\n    ret[name] = version\nreturn ret\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_repology_subrepo",
        "className": null,
        "fileName": "/tests/test_repology.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('asciiquarium', {'source': 'repology', 'repo':\n    'fedora_32', 'subrepo': 'release'}) == '1.1'\n",
        "CUT_1": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_2": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "repo = conf['pagure']\nhost = conf.get('host', 'pagure.io')\nurl = PAGURE_URL % (host, repo)\ndata = await cache.get_json(url)\nversion = data['tags']\nreturn version\n"
    },
    {
        "functionName": "test_repology_bad_subrepo",
        "className": null,
        "fileName": "/tests/test_repology.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "try:\n    assert await get_version('asciiquarium', {'source': 'repology', 'repo':\n        'fedora_32', 'subrepo': 'badsubrepo'}) is None\nexcept RuntimeError as e:\n    assert 'package is not found in subrepo' in str(e)\n",
        "CUT_1": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_2": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_3": "assert self.func is not None\ntries = entry.get('tries', None)\nif tries is not None:\n    ctx_tries.set(tries)\nproxy = entry.get('proxy', None)\nif proxy is not None:\n    ctx_proxy.set(proxy)\nua = entry.get('user_agent', None)\nif ua is not None:\n    ctx_ua.set(ua)\ntry:\n    async with self.task_sem:\n        version = await self.func(name, entry, cache=self.cache, keymanager\n            =self.keymanager)\n    await self.result_q.put(RawResult(name, version, entry))\nexcept Exception as e:\n    await self.result_q.put(RawResult(name, e, entry))\n",
        "CUT_4": "assert self.func is not None\ntries = entry.get('tries', None)\nif tries is not None:\n    ctx_tries.set(tries)\nproxy = entry.get('proxy', None)\nif proxy is not None:\n    ctx_proxy.set(proxy)\nua = entry.get('user_agent', None)\nif ua is not None:\n    ctx_ua.set(ua)\ntry:\n    async with self.task_sem:\n        version = await self.func(name, entry, cache=self.cache, keymanager\n            =self.keymanager)\n    await self.result_q.put(RawResult(name, version, entry))\nexcept Exception as e:\n    await self.result_q.put(RawResult(name, e, entry))\n",
        "CUT_5": "pkgname = conf.get('alpm', name)\ndbpath = conf.get('dbpath', '/var/lib/pacman')\nrepo = conf.get('repo')\nstrip_release = conf.get('strip_release', False)\nprovided = conf.get('provided')\ndb = (await cache.get((dbpath, repo), open_db))[1]\npkg = db.get_pkg(pkgname)\nif pkg is None:\n    raise GetVersionError('package not found in the ALPM database')\nif provided is None:\n    version = pkg.version\nelse:\n    provides = dict(x.split('=', 1) for x in pkg.provides if '=' in x)\n    version = provides.get(provided)\n    if version is None:\n        raise GetVersionError('provides element not found')\nif strip_release:\n    version = version.split('-', 1)[0]\nreturn version\n"
    },
    {
        "functionName": "test_repology_no_repo",
        "className": null,
        "fileName": "/tests/test_repology.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "try:\n    assert await get_version('ssed', {'source': 'repology'}) is None\nexcept RuntimeError as e:\n    assert 'repo field is required' in str(e)\n",
        "CUT_1": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_2": "project = conf.get('repology') or name\nrepo = conf.get('repo')\nsubrepo = conf.get('subrepo')\nif not repo:\n    raise GetVersionError('repo field is required for repology source')\nurl = API_URL.format(project)\ndata = await cache.get_json(url)\npkgs = [pkg for pkg in data if pkg['repo'] == repo]\nif not pkgs:\n    raise GetVersionError('package is not found', repo=repo)\nif subrepo:\n    pkgs = [pkg for pkg in pkgs if pkg.get('subrepo') == subrepo]\n    if not pkgs:\n        raise GetVersionError('package is not found in subrepo', repo=repo,\n            subrepo=subrepo)\nversions = [pkg['version'] for pkg in pkgs]\nreturn versions\n",
        "CUT_3": "assert self.func is not None\ntries = entry.get('tries', None)\nif tries is not None:\n    ctx_tries.set(tries)\nproxy = entry.get('proxy', None)\nif proxy is not None:\n    ctx_proxy.set(proxy)\nua = entry.get('user_agent', None)\nif ua is not None:\n    ctx_ua.set(ua)\ntry:\n    async with self.task_sem:\n        version = await self.func(name, entry, cache=self.cache, keymanager\n            =self.keymanager)\n    await self.result_q.put(RawResult(name, version, entry))\nexcept Exception as e:\n    await self.result_q.put(RawResult(name, e, entry))\n",
        "CUT_4": "assert self.func is not None\ntries = entry.get('tries', None)\nif tries is not None:\n    ctx_tries.set(tries)\nproxy = entry.get('proxy', None)\nif proxy is not None:\n    ctx_proxy.set(proxy)\nua = entry.get('user_agent', None)\nif ua is not None:\n    ctx_ua.set(ua)\ntry:\n    async with self.task_sem:\n        version = await self.func(name, entry, cache=self.cache, keymanager\n            =self.keymanager)\n    await self.result_q.put(RawResult(name, version, entry))\nexcept Exception as e:\n    await self.result_q.put(RawResult(name, e, entry))\n",
        "CUT_5": "try:\n    return await get_version_real(name, conf, **kwargs)\nexcept TemporaryError as e:\n    check_ratelimit(e, name)\n"
    },
    {
        "functionName": "test_gitlab",
        "className": null,
        "fileName": "/tests/test_gitlab.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "ver = await get_version('example', {'source': 'gitlab', 'gitlab':\n    'gitlab-org/gitlab-test'})\nassert len(ver) == 8\nassert ver.isdigit()\n",
        "CUT_1": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_2": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_3": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n",
        "CUT_4": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n",
        "CUT_5": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_gitlab_max_tag",
        "className": null,
        "fileName": "/tests/test_gitlab.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'gitlab', 'gitlab':\n    'gitlab-org/gitlab-test', 'use_max_tag': True}) == 'v1.1.1'\n",
        "CUT_1": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_2": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_3": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n",
        "CUT_4": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n",
        "CUT_5": "repo = conf['bitbucket']\nbr = conf.get('branch', '')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = BITBUCKET_MAX_TAG % repo\n    max_page = conf.get('max_page', 3)\n    data = await _get_tags(url, max_page=max_page, cache=cache)\nelse:\n    url = BITBUCKET_URL % (repo, br)\n    data = await cache.get_json(url)\nif use_max_tag:\n    version = data\nelse:\n    version = data['values'][0]['date'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_gitlab_max_tag_with_include",
        "className": null,
        "fileName": "/tests/test_gitlab.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'gitlab', 'gitlab':\n    'gitlab-org/gitlab-test', 'use_max_tag': True, 'include_regex': 'v1\\\\.0.*'}\n    ) == 'v1.0.0'\n",
        "CUT_1": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_2": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_3": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n",
        "CUT_4": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n",
        "CUT_5": "headers = {'Accept': 'application/vnd.npm.install-v1+json', 'Range':\n    'bytes=0-1023'}\nres = await session.get(url, headers=headers)\nreturn res.body\n"
    },
    {
        "functionName": "test_gitlab_max_tag_with_ignored",
        "className": null,
        "fileName": "/tests/test_gitlab.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'gitlab', 'gitlab':\n    'gitlab-org/gitlab-test', 'use_max_tag': True, 'ignored': 'v1.1.0 v1.1.1'}\n    ) == 'v1.0.0'\n",
        "CUT_1": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_2": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n",
        "CUT_3": "headers = {'Accept': 'application/vnd.npm.install-v1+json', 'Range':\n    'bytes=0-1023'}\nres = await session.get(url, headers=headers)\nreturn res.body\n",
        "CUT_4": "headers = {'Accept': 'application/vnd.npm.install-v1+json', 'Range':\n    'bytes=0-1023'}\nres = await session.get(url, headers=headers)\nreturn res.body\n",
        "CUT_5": "res = exc.response\nif not res:\n    raise\nn = int(res.headers.get('RateLimit-Remaining', -1))\nif n == 0:\n    logger.error(\n        'gitlab rate limited. Wait some time or get an API token to increase the allowance if not yet'\n        , name=name)\nelse:\n    raise\n"
    },
    {
        "functionName": "test_pagure",
        "className": null,
        "fileName": "/tests/test_pagure.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "ver = await get_version('example', {'source': 'pagure', 'pagure':\n    'nvchecker-test'})\nassert ver == '0.2'\n",
        "CUT_1": "repo = conf['pagure']\nhost = conf.get('host', 'pagure.io')\nurl = PAGURE_URL % (host, repo)\ndata = await cache.get_json(url)\nversion = data['tags']\nreturn version\n",
        "CUT_2": "repo = conf['pagure']\nhost = conf.get('host', 'pagure.io')\nurl = PAGURE_URL % (host, repo)\ndata = await cache.get_json(url)\nversion = data['tags']\nreturn version\n",
        "CUT_3": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_4": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_5": "confdir = appdirs.user_config_dir(appname='nvchecker')\nfile = os.path.join(confdir, 'nvchecker.toml')\nreturn file\n"
    },
    {
        "functionName": "test_pagure_with_ignored",
        "className": null,
        "fileName": "/tests/test_pagure.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "ver = await get_version('example', {'source': 'pagure', 'pagure':\n    'nvchecker-test', 'ignored': '0.2'})\nassert ver == '0.1'\n",
        "CUT_1": "repo = conf['pagure']\nhost = conf.get('host', 'pagure.io')\nurl = PAGURE_URL % (host, repo)\ndata = await cache.get_json(url)\nversion = data['tags']\nreturn version\n",
        "CUT_2": "repo = conf['pagure']\nhost = conf.get('host', 'pagure.io')\nurl = PAGURE_URL % (host, repo)\ndata = await cache.get_json(url)\nversion = data['tags']\nreturn version\n",
        "CUT_3": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_4": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_5": "confdir = appdirs.user_config_dir(appname='nvchecker')\nfile = os.path.join(confdir, 'nvchecker.toml')\nreturn file\n"
    },
    {
        "functionName": "test_pagure_with_alternative_host",
        "className": null,
        "fileName": "/tests/test_pagure.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "ver = await get_version('example', {'source': 'pagure', 'pagure':\n    'rpms/glibc', 'host': 'src.fedoraproject.org', 'include_regex':\n    'F-\\\\d+-start'})\nassert ver == 'F-13-start'\n",
        "CUT_1": "repo = conf['pagure']\nhost = conf.get('host', 'pagure.io')\nurl = PAGURE_URL % (host, repo)\ndata = await cache.get_json(url)\nversion = data['tags']\nreturn version\n",
        "CUT_2": "repo = conf['pagure']\nhost = conf.get('host', 'pagure.io')\nurl = PAGURE_URL % (host, repo)\ndata = await cache.get_json(url)\nversion = data['tags']\nreturn version\n",
        "CUT_3": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_4": "try:\n    with open(file) as f:\n        data = f.read()\nexcept FileNotFoundError:\n    return {}\ntry:\n    v = json.loads(data)\nexcept json.decoder.JSONDecodeError:\n    v = {}\n    for l in data.splitlines():\n        name, ver = l.rstrip().split(None, 1)\n        v[name] = ver\nreturn v\n",
        "CUT_5": "repo = urllib.parse.quote_plus(conf['gitlab'])\nbr = conf.get('branch', 'master')\nhost = conf.get('host', 'gitlab.com')\nuse_max_tag = conf.get('use_max_tag', False)\nif use_max_tag:\n    url = GITLAB_MAX_TAG % (host, repo)\nelse:\n    url = GITLAB_URL % (host, repo, br)\ntoken = conf.get('token')\nif token is None:\n    key_name = 'gitlab_' + host.lower()\n    token = keymanager.get_key(key_name)\nheaders = {}\nif token:\n    headers['PRIVATE-TOKEN'] = token\ndata = await cache.get_json(url, headers=headers)\nif use_max_tag:\n    version = [tag['name'] for tag in data]\nelse:\n    version = data[0]['created_at'].split('T', 1)[0].replace('-', '')\nreturn version\n"
    },
    {
        "functionName": "test_apt",
        "className": null,
        "fileName": "/tests/test_apt.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'apt',\n    'mirror': 'http://deb.debian.org/debian/', 'suite': 'sid'}) == '0.1.7-1'\n",
        "CUT_1": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_2": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_3": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_4": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_5": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n"
    },
    {
        "functionName": "test_apt_srcpkg",
        "className": null,
        "fileName": "/tests/test_apt.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('test', {'source': 'apt', 'srcpkg':\n    'golang-github-dataence-porter2', 'mirror':\n    'http://deb.debian.org/debian/', 'suite': 'sid'}\n    ) == '0.0~git20150829.56e4718-2'\n",
        "CUT_1": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_2": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_4": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_5": "cache, url = key\napt_packages = await cache.get(url, get_url)\npkg_map = {}\nsrcpkg_map = {}\npkg = None\nsrcpkg = None\nfor line in apt_packages.split('\\n'):\n    if line.startswith('Package: '):\n        pkg = line[9:]\n    elif line.startswith('Source: '):\n        srcpkg = line[8:]\n    elif line.startswith('Version: '):\n        version = line[9:]\n        if pkg is not None:\n            pkg_map[pkg] = version\n        if srcpkg is not None:\n            srcpkg_map[srcpkg] = version\n        pkg = srcpkg = None\nreturn pkg_map, srcpkg_map\n"
    },
    {
        "functionName": "test_apt_strip_release",
        "className": null,
        "fileName": "/tests/test_apt.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'apt',\n    'mirror': 'http://deb.debian.org/debian/', 'suite': 'sid',\n    'strip_release': 1}) == '0.1.7'\n",
        "CUT_1": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_2": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_3": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_4": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_5": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n"
    },
    {
        "functionName": "test_apt_deepin",
        "className": null,
        "fileName": "/tests/test_apt.py",
        "projectName": "nvchecker",
        "Label": 1,
        "isTest": true,
        "Body": "assert await get_version('sigrok-firmware-fx2lafw', {'source': 'apt',\n    'mirror': 'https://community-packages.deepin.com/deepin', 'suite':\n    'apricot'}) == '0.1.6-1'\n",
        "CUT_1": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_2": "srcpkg = conf.get('srcpkg')\npkg = conf.get('pkg')\nmirror = conf['mirror']\nsuite = conf['suite']\nrepo = conf.get('repo', 'main')\narch = conf.get('arch', 'amd64')\nstrip_release = conf.get('strip_release', False)\nif srcpkg and pkg:\n    raise GetVersionError('Setting both srcpkg and pkg is ambigious')\nelif not srcpkg and not pkg:\n    pkg = name\napt_release = await cache.get(APT_RELEASE_URL % (mirror, suite), get_url)\nfor suffix in APT_PACKAGES_SUFFIX_PREFER:\n    packages_path = APT_PACKAGES_PATH % (repo, arch, suffix)\n    if ' ' + packages_path in apt_release:\n        break\nelse:\n    raise GetVersionError('Packages file not found in APT repository')\npkg_map, srcpkg_map = await cache.get((cache, APT_PACKAGES_URL % (mirror,\n    suite, packages_path)), parse_packages)\nif pkg and pkg in pkg_map:\n    version = pkg_map[pkg]\nelif srcpkg and srcpkg in srcpkg_map:\n    version = srcpkg_map[srcpkg]\nelse:\n    raise GetVersionError('package not found in APT repository')\nif strip_release:\n    version = version.split('-')[0]\nreturn version\n",
        "CUT_3": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_4": "pkg = conf.get('debianpkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite') or 'sid'\nurl = URL % {'pkgname': pkg, 'suite': suite}\ndata = await cache.get_json(url)\nif not data.get('versions'):\n    raise GetVersionError('Debian package not found')\nr = data['versions'][0]\nif strip_release:\n    version = r['version'].split('-')[0]\nelse:\n    version = r['version']\nreturn version\n",
        "CUT_5": "pkg = conf.get('ubuntupkg') or name\nstrip_release = conf.get('strip_release', False)\nsuite = conf.get('suite')\nurl = URL % pkg\nif suite:\n    suite = 'https://api.launchpad.net/1.0/ubuntu/' + suite\nreleases = []\nwhile not releases:\n    data = await cache.get_json(url)\n    if not data.get('entries'):\n        raise GetVersionError('Ubuntu package not found')\n    releases = [r for r in data['entries'] if r['status'] == 'Published']\n    if suite:\n        releases = [r for r in releases if r['distro_series_link'] == suite]\n    if 'next_collection_link' not in data:\n        break\n    url = data['next_collection_link']\nif not releases:\n    raise GetVersionError('Ubuntu package not found')\n    return\nif strip_release:\n    version = releases[0]['source_package_version'].split('-')[0]\nelse:\n    version = releases[0]['source_package_version']\nreturn version\n"
    },
    {
        "functionName": "test_substitute_prefix",
        "className": null,
        "fileName": "/tests/test_substitute.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'manual', 'manual': 'v1.0',\n    'prefix': 'v'}) == '1.0'\n",
        "CUT_1": "return str(conf.get('manual')).strip() or None\n",
        "CUT_2": "return str(conf.get('manual')).strip() or None\n",
        "CUT_3": "description = 'Generates plain unix manual documents.  ' + default_description\npublish_cmdline(writer=MyWriter(), description=description)\n",
        "CUT_4": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_5": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n"
    },
    {
        "functionName": "test_substitute_prefix_missing_ok",
        "className": null,
        "fileName": "/tests/test_substitute.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'manual', 'manual': '1.0',\n    'prefix': 'v'}) == '1.0'\n",
        "CUT_1": "return str(conf.get('manual')).strip() or None\n",
        "CUT_2": "return str(conf.get('manual')).strip() or None\n",
        "CUT_3": "description = 'Generates plain unix manual documents.  ' + default_description\npublish_cmdline(writer=MyWriter(), description=description)\n",
        "CUT_4": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_5": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n"
    },
    {
        "functionName": "test_substitute_regex",
        "className": null,
        "fileName": "/tests/test_substitute.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'manual', 'manual': 'r15c',\n    'from_pattern': 'r(\\\\d+)([a-z])', 'to_pattern': 'r\\\\1.\\\\2'}) == 'r15.c'\n",
        "CUT_1": "return str(conf.get('manual')).strip() or None\n",
        "CUT_2": "return str(conf.get('manual')).strip() or None\n",
        "CUT_3": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_4": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_5": "description = 'Generates plain unix manual documents.  ' + default_description\npublish_cmdline(writer=MyWriter(), description=description)\n"
    },
    {
        "functionName": "test_substitute_regex_missing_ok",
        "className": null,
        "fileName": "/tests/test_substitute.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'manual', 'manual': 'r15',\n    'from_pattern': 'r(\\\\d+)([a-z])', 'to_pattern': 'r\\\\1.\\\\2'}) == 'r15'\n",
        "CUT_1": "return str(conf.get('manual')).strip() or None\n",
        "CUT_2": "return str(conf.get('manual')).strip() or None\n",
        "CUT_3": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_4": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_5": "description = 'Generates plain unix manual documents.  ' + default_description\npublish_cmdline(writer=MyWriter(), description=description)\n"
    },
    {
        "functionName": "test_substitute_regex_empty_to_pattern",
        "className": null,
        "fileName": "/tests/test_substitute.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'manual', 'manual':\n    '15-debian', 'from_pattern': '-\\\\w+$', 'to_pattern': ''}) == '15'\n",
        "CUT_1": "return str(conf.get('manual')).strip() or None\n",
        "CUT_2": "return str(conf.get('manual')).strip() or None\n",
        "CUT_3": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_4": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_5": "description = 'Generates plain unix manual documents.  ' + default_description\npublish_cmdline(writer=MyWriter(), description=description)\n"
    },
    {
        "functionName": "test_substitute_prefix_has_higher_priority",
        "className": null,
        "fileName": "/tests/test_substitute.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'manual', 'manual': 'r15',\n    'prefix': 'r', 'from_pattern': 'r(\\\\d+)', 'to_pattern': 'R\\\\1'}) == '15'\n",
        "CUT_1": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_2": "\"\"\"\n  Substitute the version string via defined rules in the configuration file.\n  See README.rst#global-options for details.\n  \"\"\"\nprefix = conf.get('prefix')\nif prefix:\n    if version.startswith(prefix):\n        version = version[len(prefix):]\n    return version\nfrom_pattern = conf.get('from_pattern')\nif from_pattern:\n    to_pattern = conf.get('to_pattern')\n    if to_pattern is None:\n        raise ValueError(\"from_pattern exists but to_pattern doesn't\")\n    return re.sub(from_pattern, to_pattern, version)\nreturn version\n",
        "CUT_3": "return str(conf.get('manual')).strip() or None\n",
        "CUT_4": "return str(conf.get('manual')).strip() or None\n",
        "CUT_5": "description = 'Generates plain unix manual documents.  ' + default_description\npublish_cmdline(writer=MyWriter(), description=description)\n"
    },
    {
        "functionName": "test_cache",
        "className": null,
        "fileName": "/tests/test_cache.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "conf = \"\"\"\n[cache-1]\nsource = \"cmd\"\ncmd = \"bash -c 'echo $RANDOM'\"\n\n[cache-2]\nsource = \"cmd\"\ncmd = \"bash -c 'echo $RANDOM'\\\"\n\"\"\"\nr = await run_str_multi(conf)\nassert r['cache-1'] == r['cache-2']\n",
        "CUT_1": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_2": "cmd = conf['cmd']\nreturn await cache.get(cmd, run_cmd)\n",
        "CUT_3": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_4": "logger.debug('running cmd', cmd=cmd)\np = await asyncio.create_subprocess_shell(cmd, stdout=asyncio.subprocess.\n    PIPE, stderr=asyncio.subprocess.PIPE)\noutput, error = await p.communicate()\noutput_s = output.strip().decode('latin1')\nerror_s = error.strip().decode(errors='replace')\nif p.returncode != 0:\n    raise GetVersionError('command exited with error', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelif not output_s:\n    raise GetVersionError('command exited without output', cmd=cmd, error=\n        error_s, returncode=p.returncode)\nelse:\n    return output_s\n",
        "CUT_5": "self.cache = {}\n"
    },
    {
        "functionName": "test_sparkle",
        "className": null,
        "fileName": "/tests/test_sparkle.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'sparkle', 'sparkle':\n    'https://sparkle-project.org/files/sparkletestcast.xml'}) == '2.0'\n",
        "CUT_1": "sparkle = conf['sparkle']\nreturn await cache.get(sparkle, get_version_impl)\n",
        "CUT_2": "sparkle = conf['sparkle']\nreturn await cache.get(sparkle, get_version_impl)\n",
        "CUT_3": "res = await session.get(sparkle)\nroot = ElementTree.fromstring(res.body)\nitem = root.find('./channel/item[1]/enclosure')\nversion_string = item.get(\n    '{http://www.andymatuschak.org/xml-namespaces/sparkle}shortVersionString')\nbuild_number = item.get(\n    '{http://www.andymatuschak.org/xml-namespaces/sparkle}version')\nif (version_string and version_string.isdigit()) and (build_number and not\n    build_number.isdigit()):\n    version_string, build_number = build_number, version_string\nversion = []\nif version_string:\n    version.append(version_string)\nif build_number and build_number not in version:\n    version.append(build_number)\nreturn '-'.join(version) if version else None\n",
        "CUT_4": "res = await session.get(sparkle)\nroot = ElementTree.fromstring(res.body)\nitem = root.find('./channel/item[1]/enclosure')\nversion_string = item.get(\n    '{http://www.andymatuschak.org/xml-namespaces/sparkle}shortVersionString')\nbuild_number = item.get(\n    '{http://www.andymatuschak.org/xml-namespaces/sparkle}version')\nif (version_string and version_string.isdigit()) and (build_number and not\n    build_number.isdigit()):\n    version_string, build_number = build_number, version_string\nversion = []\nif version_string:\n    version.append(version_string)\nif build_number and build_number not in version:\n    version.append(build_number)\nreturn '-'.join(version) if version else None\n",
        "CUT_5": "package = conf.get('pypi') or name\nuse_pre_release = conf.get('use_pre_release', False)\nurl = 'https://pypi.org/pypi/{}/json'.format(package)\ndata = await cache.get_json(url)\nif use_pre_release:\n    version = sorted(data['releases'].keys(), key=parse_version)[-1]\nelse:\n    version = data['info']['version']\nreturn version\n"
    },
    {
        "functionName": "test_manual",
        "className": null,
        "fileName": "/tests/test_manual.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'manual', 'manual': 'Meow'}\n    ) == 'Meow'\n",
        "CUT_1": "return str(conf.get('manual')).strip() or None\n",
        "CUT_2": "return str(conf.get('manual')).strip() or None\n",
        "CUT_3": "description = 'Generates plain unix manual documents.  ' + default_description\npublish_cmdline(writer=MyWriter(), description=description)\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_pypi",
        "className": null,
        "fileName": "/tests/test_pypi.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example', {'source': 'pypi'}) == '0.1.0'\n",
        "CUT_1": "package = conf.get('pypi') or name\nuse_pre_release = conf.get('use_pre_release', False)\nurl = 'https://pypi.org/pypi/{}/json'.format(package)\ndata = await cache.get_json(url)\nif use_pre_release:\n    version = sorted(data['releases'].keys(), key=parse_version)[-1]\nelse:\n    version = data['info']['version']\nreturn version\n",
        "CUT_2": "package = conf.get('pypi') or name\nuse_pre_release = conf.get('use_pre_release', False)\nurl = 'https://pypi.org/pypi/{}/json'.format(package)\ndata = await cache.get_json(url)\nif use_pre_release:\n    version = sorted(data['releases'].keys(), key=parse_version)[-1]\nelse:\n    version = data['info']['version']\nreturn version\n",
        "CUT_3": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "exc = GetVersionError('no source specified')\nasync with self.task_sem:\n    for name, conf in self.tasks:\n        await self.result_q.put(RawResult(name, exc, conf))\n"
    },
    {
        "functionName": "test_pypi_release",
        "className": null,
        "fileName": "/tests/test_pypi.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example-test-package', {'source': 'pypi', 'pypi':\n    'example-test-package'}) == '1.0.0'\n",
        "CUT_1": "package = conf.get('pypi') or name\nuse_pre_release = conf.get('use_pre_release', False)\nurl = 'https://pypi.org/pypi/{}/json'.format(package)\ndata = await cache.get_json(url)\nif use_pre_release:\n    version = sorted(data['releases'].keys(), key=parse_version)[-1]\nelse:\n    version = data['info']['version']\nreturn version\n",
        "CUT_2": "package = conf.get('pypi') or name\nuse_pre_release = conf.get('use_pre_release', False)\nurl = 'https://pypi.org/pypi/{}/json'.format(package)\ndata = await cache.get_json(url)\nif use_pre_release:\n    version = sorted(data['releases'].keys(), key=parse_version)[-1]\nelse:\n    version = data['info']['version']\nreturn version\n",
        "CUT_3": "config.addinivalue_line('markers',\n    'needs_net: mark test to require Internet access')\n",
        "CUT_4": "\"\"\"Override pytest-asyncio's event_loop fixture,\n     Don't create an instance of the default event loop for each test case.\n     We need the same ioloop across tests for the aiohttp support.\n  \"\"\"\nloop = asyncio.get_event_loop()\nyield loop\npytest.fixture(scope='session')",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    },
    {
        "functionName": "test_pypi_pre_release",
        "className": null,
        "fileName": "/tests/test_pypi.py",
        "projectName": "nvchecker",
        "Label": 0,
        "isTest": true,
        "Body": "assert await get_version('example-test-package', {'source': 'pypi',\n    'use_pre_release': 1}) == '1.0.1a1'\n",
        "CUT_1": "package = conf.get('pypi') or name\nuse_pre_release = conf.get('use_pre_release', False)\nurl = 'https://pypi.org/pypi/{}/json'.format(package)\ndata = await cache.get_json(url)\nif use_pre_release:\n    version = sorted(data['releases'].keys(), key=parse_version)[-1]\nelse:\n    version = data['info']['version']\nreturn version\n",
        "CUT_2": "package = conf.get('pypi') or name\nuse_pre_release = conf.get('use_pre_release', False)\nurl = 'https://pypi.org/pypi/{}/json'.format(package)\ndata = await cache.get_json(url)\nif use_pre_release:\n    version = sorted(data['releases'].keys(), key=parse_version)[-1]\nelse:\n    version = data['info']['version']\nreturn version\n",
        "CUT_3": "config.addinivalue_line('markers',\n    'needs_net: mark test to require Internet access')\n",
        "CUT_4": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n",
        "CUT_5": "mods: Dict[str, Tuple[types.ModuleType, List]] = {}\nctx_tries.set(tries)\nroot_ctx = contextvars.copy_context()\nfor name, entry in entries.items():\n    source = entry.get('source', 'none')\n    if source not in mods:\n        mod = import_module('nvchecker_source.' + source)\n        tasks: List[Tuple[str, Entry]] = []\n        mods[source] = mod, tasks\n        config = source_configs.get(source)\n        if config and getattr(mod, 'configure'):\n            mod.configure(config)\n    else:\n        tasks = mods[source][1]\n    tasks.append((name, entry))\nret = []\nfor mod, tasks in mods.values():\n    if hasattr(mod, 'Worker'):\n        worker_cls = mod.Worker\n    else:\n        worker_cls = FunctionWorker\n    ctx = root_ctx.copy()\n    worker = ctx.run(worker_cls, task_sem, result_q, tasks, keymanager)\n    if worker_cls is FunctionWorker:\n        func = mod.get_version\n        ctx.run(worker.initialize, func)\n    ret.append(ctx.run(worker.run))\nreturn ret\n"
    }
]